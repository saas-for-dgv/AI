{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMlMvLkgmjszq7g4+Kbzz8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saas-for-dgv/AI/blob/main/1_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is biagram model?\n",
        "\n",
        "Biagram models is all about predicting the next character. This code possibly goes through a large set of data, only to predict what my next character is. Is it so?\n",
        "\n",
        "How do I use it?\n",
        "\n",
        "Implement this in an artificial neural network to train the network."
      ],
      "metadata": {
        "id": "EkD3m8ZKSHcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to enable word-wrap in outputs\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre { white-space: pre-wrap; }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n"
      ],
      "metadata": {
        "id": "sNn322YiKHPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8La1mADU74wM"
      },
      "outputs": [],
      "source": [
        "# check for gpu/cpu\n",
        "import torch\n",
        "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# Hyper parameters for training\n",
        "block_size = 8\n",
        "batch_size = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: clone from my github repo where I am saving this notebook\n",
        "\n",
        "!git clone https://github.com/saas-for-dgv/AI.git\n"
      ],
      "metadata": {
        "id": "NG2osphF-ZHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a python code to read wizard_of_oz.txt from AI folder and print the first 20 chars of those files\n",
        "\n",
        "with open('AI/wizard_of_oz.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "print(\"vocab size =\",len(chars))"
      ],
      "metadata": {
        "id": "hfGSBVS9H_h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = {ch:i for i, ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join(int_to_string[i] for i in l)\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "id": "HOF7aGR3PklG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "WhMb0_X8PodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print('when input is ',context,' target is ',target)"
      ],
      "metadata": {
        "id": "DFk7P1IFPv8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}